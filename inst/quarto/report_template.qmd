---
title: "Differential hPTM Usage"
format: html
params:
  ds_path: "input_data.rds"
  histone_params: !expr list()
  msa_params: !expr list()
  mod_params: !expr list()
  contaminant_params: !expr list()
  usage_params: !expr list()
  variant_usage_level: "histone"
  reference_levels: !expr NULL
  reference_levels_names: !expr NULL
  design_formula: "~ 0 + group"
  design_formula_names: "factor"
  random_effects: !expr NULL
  contrasts: !expr NULL
  contrasts_names: !expr NULL
  generate_lineplots: "none"
---

## Overview

This workflow is an adaptation of msqrob2PTM^[Demeulemeester, N., Gébelin, M., Caldi Gomes, L., Lingor, P., Carapito, C., Martens, L., & Clement, L. (2024). msqrob2PTM: Differential Abundance and Differential Usage Analysis of MS-Based Proteomics Data at the Posttranslational Modification and Peptidoform Level. Molecular & Cellular Proteomics, 23(2), 100708. https://doi.org/10.1016/j.mcpro.2023.100708].
In brief, data is imported, preprocessed, normalized (to allow usage calculation), and tested for differential usage of histone variants, histone peptidoforms, and hPTMs.
The dataset will be parsed in @sec-parsing, preprocessed in @sec-preprocessing, and differential usage analysis is then performed in @sec-da. Finally, static plots and assays can be exported in @sec-export.

We start by importing the relevant packages.

```{r}
#| label: chunk-libraries
#| output: false

# tidyverse
library(dplyr)
library(purrr)
library(tibble)
library(stringr)
library(forcats)
# proteomics
library(QFeatures)
library(msqrob2)
# plotting
library(ggplot2)
library(ggbreak)
# hPTM usage
# TODO library(hptmUsage)
devtools::load_all(path = "/workspaces/hptmUsage")
```

## Data parsing {#sec-parsing}

The hPTM dataset (e.g., a peptide ion export, not deconvoluted, including all identified features and properties from Progenesis QIP) was imported using the `hptmUsage::readProgenesis()` function and metadata was added (manually or using the `hptmUsage::replaceColData()` function).
This data is contained in a QFeatures^[Gatto, L., & Vanderaa, C. (2024). QFeatures: Quantitative features for mass spectrometry data. https://doi.org/10.18129/B9.bioc.QFeatures] object, which will store all information relevant to the dataset from here on.

```{r}
#| label: tbl-import
#| panel: tabset
#| results: asis
#| echo: false
#| column: page-right

pe <- readRDS(params$ds_path)

# print data embedded in the QFeatures object as sanity check
cat("\n### Precursor metadata\n\n")
as_tibble(rowData(pe[["precursorRaw"]]))
cat("\n### Sample metadata\n\n")
as_tibble(colData(pe))
```

### Alignment and hPTM processing

Now, we retrieve the relevant histone sequences and add them to their corresponding histone family multiple sequence alignment (MSA) as retrieved from HistoneDB 2.0^[Draizen, E. J.; Shaytan, A. K.; Mariño-Ramírez, L.; Talbert, P. B.; Landsman, D.; Panchenko, A. R. HistoneDB 2.0: A Histone Database with Variants—an Integrated Resource to Explore Histones and Their Variants. Database (Oxford) 2016, 2016, baw014. https://doi.org/10.1093/database/baw014.].
Then, we process all identified peptidoforms to map them to their relevant histone family, clean up hPTM annotation, and **map hPTMs to their "canonical location"** (by default), i.e., the corresponding amino acid index of the canonical sequence within the MSA.

```{r}
#| label: chunk-alignment

histones <- do.call(histonesFromUniprot, params$histone_params)
histones <- do.call(alignHistones, rlang::list2(unaligned_histones = histones, !!!params$msa_params))
pe <- matchHistones(pe, histones$unaligned, 1, progress = FALSE)
pe <- do.call(processMods, rlang::list2(object = pe, msa = histones, i = 1, !!!params$mod_params))
```

```{css, echo = FALSE}
/* custom css class for scrollable container */
.scrolling-msa {
  overflow-x: auto;
  overflow-y: hidden;
  width: 100%;
}

/* override quarto (= bootstrap) default shrinking */
.scrolling-msa img {
  max-width: none !important;
  width: auto;
}
```

The following MSA plots can be used as a visual reference for hPTM indexes.

::: {.column-page}

:::: {.panel-tabset}

```{r}
#| results: asis
#| fig-height: 2
#| fig-width: 15
#| fig-dpi: 600
#| out-width: 200%
#| warning: false
#| message: false

if (is.null(params$histone_params$histone_families)) {
  histone_families <- c("H1", "H2A", "H2B", "H3", "H4")
} else {
  histone_families <- params$histone_params$histone_families
}

# inspect the alignment of all families in tabset? Visualize the parsed results
for (histone_family in histone_families) {
  # quarto programmatic tabset
  cat("#### ", histone_family, " MSA", "\n\n", sep = "")
  # MSA plot
  p <- ggmsa::ggmsa(
    c(histones$msa[[histone_family]], histones$msa_ref[[histone_family]]),
    char_width = .5,
    seq_name = TRUE,
    consensus_views = TRUE,
    use_dot = FALSE,
    disagreement = FALSE,
    ignore_gaps = FALSE,
    ref = names(histones$msa_ref[[histone_family]])
  ) +
    theme(axis.text = element_text(size = 1000 / width(histones$msa[[histone_family]])[[1]]))
  # plot in scrollable container
  cat("\n\n::::: {.scrolling-msa}\n\n")
  print(p)
  cat("\n\n:::::\n\n")
  # TODO save plot
  fs::dir_create(fs::path(quarto::get_running_project_root(), "/out/floats/"))
  # ggplot2::ggsave(fs::path(quarto::get_running_project_root(), "/out/floats/fig-", histone_family, "-msa", ext = "png"), dpi = 300, plot = p)
  # end quarto programmatic tabset
  cat("\n\n")
}
```

::::

:::

## Data preprocessing {#sec-preprocessing}

### QC

Inspect the peptide loading consistency and histone extraction efficiency.
Ideally, both histone extraction efficiency (increasing along the main diagonal from top left to bottom right) and histone loading (increasing along the x-axis) should be mostly constant and independent of the biological condition.
If a batch effect is visible here, consider adding it to the model during differential usage testing.

```{r}
#| label: fig-extraction
#| fig-cap: "Evaluation of histone loading per extraction batch"
#| warning: false
#| message: false

# sample loading
nonhistone_assay <- assay(pe[!rowData(pe[["precursorRaw"]])$histone, ], "precursorRaw")
median_raw_coextr_abundance <- colMedians(log1p(nonhistone_assay), na.rm = TRUE)
colData(pe)[names(median_raw_coextr_abundance), "median_raw_coextr_abundance"] <- median_raw_coextr_abundance
# histone loading
histone_assay <- assay(pe[rowData(pe[["precursorRaw"]])$histone, ], "precursorRaw")
median_raw_histone_abundance <- colMedians(log1p(histone_assay), na.rm = TRUE)
colData(pe)[names(median_raw_histone_abundance), "median_raw_histone_abundance"] <- median_raw_histone_abundance
# extraction efficiency
pe$extraction_efficiency <- pe$median_raw_histone_abundance / pe$median_raw_coextr_abundance
# visualize loading consistency / histone extraction efficiency
p <- ggplot(
  colData(pe[, !grepl("QC_", pe$quantCols)]),
  aes(x = median_raw_histone_abundance, y = median_raw_coextr_abundance, color = group)
) +
  geom_point(aes(shape = outlier, size = extraction_efficiency)) +
  geom_smooth(aes(color = NULL), se = FALSE) +
  geom_abline(intercept = 0, slope = 1) +
  scale_size(range = c(2, 3))
p <- ggExtra::ggMarginal(
  p,
  mapping = aes(fill = colData(pe[, !grepl("QC_", pe$quantCols)])$group),
  position = "stack",
  alpha = .6
)
grid::grid.newpage()
grid::grid.draw(p)
```

### Global normalization

Normalization of the samples is performed in two steps:

1. Removal of technical variation, such as from sample loading differences, using variance stabilization (VSN)^[Huber, W., von Heydebreck, A., Sültmann, H., Poustka, A., & Vingron, M. (2002). Variance stabilization applied to microarray data calibration and to the quantification of differential expression. Bioinformatics, 18(suppl_1), S96–S104. https://doi.org/10.1093/bioinformatics/18.suppl_1.S96].
This normalizes all samples based on the abundance distribution of all precursors
2. Correction of nucleosome (or family/variant) abundance differences to allow differential **usage** analysis of histone variants, peptidoforms, and PTMs.

Here, we start with the global VSN normalization and evaluate the results.

::: {.column-page}

```{r}
#| label: fig-vsn
#| fig-cap: "Evaluation of global normalization"
#| fig-subcap:
#|   - "MeanSdPlot for quality check of VSN normalization: the red line should be approximately horizontal"
#|   - "Density plot of normalized precursor abundances per sample, coloured by extraction batch"
#|   - "Boxplot of normalized precursor abundances per sample, coloured by extraction batch"
#| layout-ncol: 3
#| message: false
#| warning: false

# VSN requires the non-log transformed values as it glog transforms the data
pe <- zeroIsNA(pe, i = "precursorRaw") |>
  normalize(
    i = "precursorRaw",
    method = "vsn",
    name = "precursor",
    verbose = FALSE,
    # while the below decreases the number of features used, it is more robust
    lts.quantile = .5,
  )

# normalized histone abundances
histone_assay <- assay(pe[rowData(pe[["precursor"]])$histone, ], "precursor")
median_histone_abundance <- colMedians(histone_assay, na.rm = TRUE)
colData(pe)[names(median_histone_abundance), "median_histone_abundance"] <- median_histone_abundance

# visualize
vsn::meanSdPlot(assay(pe[["precursor"]]), ranks = TRUE)
limma::plotDensities(assay(pe[["precursor"]]), group = pe$group, legend = "topright")
boxplot(assay(pe[["precursor"]]), col = pe$group, ylab = "Intensity")
```

:::

Feature abundance distributions should overlap well and the variance should be mostly stable across the means.
Oftentimes we see a hump at lower abundances, which mostly stems from false identification transfer between runs during feature alignment in Progenesis QIP;
therefore, the ID transfer of important low abundance features should always be manually verified.

### Filtering

Now we can drop outlier samples and filter low quality features, i.e., those possibly from contaminants and those with high missingness.

```{r}
#| label: fig-families
#| fig-cap: "Number of unique precursors (peptide + charge + modifications if any) quantified per histone family"
#| message: false

# drop outlier samples
pe <- pe[, !pe$outlier]
# drop contaminant features
rows_before_filter <- nrow(pe[["precursor"]])
pe <- do.call(tagContaminants, rlang::list2(object = pe, i = "precursor", !!!params$contaminant_params)) |>
  filterFeatures(~ !contaminant, keep = TRUE)
# remove high missing features
# at least 3 samples should have the precursor quantified + at least 50% across
rowData(pe[["precursor"]]) <- rowData(pe[["precursor"]]) |>
  cbind(nNA(pe, i = "precursor")$nNArows[c("nNA", "pNA")])
pe <- pe |>
  filterFeatures(
    VariableFilter("nNA", ncols(pe)[["precursor"]] - 3, "<="),
    i = "precursor",
    keep = TRUE
  ) |>
  filterFeatures(~ pNA < .5, i = "precursor", keep = TRUE)

# plot remaining
rowData(pe[rowData(pe[["precursor"]])$histone, ][["precursor"]]) |>
  ggplot(aes(
    x = histone_family,
    fill = !is.na(mods_pep) &
      !sapply(str_split(mods_pep, ";"), \(x) all(grepl("Unmod", x)))
  )) +
  geom_bar() +
  labs(fill = "Modified")
```

This leaves us with `r nrow(pe[["precursor"]])` observations (`r rows_before_filter - nrow(pe[["precursor"]])`
rows dropped).

### Exploratory data analysis

Peptide-level MDS plots, color-coded according to the metadata, will show the level of similarity between samples.
Look for any obvious clustering or other trends such as from loading differences. Do note that this is based on all peptide data, including from co-extracts.

```{r}
#| label: chunk-plotlyinit
#| include: false
#| echo: false

htmltools::tagList(plotly::plot_ly()) # initialize plot_ly for tabsets
```

```{r}
#| panel: tabset
#| results: asis

# MDS calculations
mds_assay <- limma::plotMDS(assay(pe[["precursor"]]), plot = FALSE) |>
  _[c("x", "y", "var.explained")] |>
  data.frame() |>
  cbind(colData(pe))
# plot
tabs <- colnames(colData(pe))[!colnames(colData(pe)) %in% c("outlier", "quantCols", "original_name")]
for (fill_col in tabs) {
  cat("#### ", fill_col, "\n\n", sep = "")
  p <- ggplot(mds_assay, mapping = aes(
    x = x, y = y, fill = .data[[fill_col]],
    size = pe$median_histone_abundance, annotation = rownames(mds_assay)
  )) +
    geom_point(colour = "black", shape = 21) +
    theme_bw() +
    xlab(paste("Leading logFC dim 1 (", round(100 * mds_assay$var.explained[[1]], 2), "%)", sep = "")) +
    ylab(paste("Leading logFC dim 2 (", round(100 * mds_assay$var.explained[[2]], 2), "%)", sep = ""))
  p |>
    plotly::ggplotly() |>
    htmltools::tagList() |>
    print()
  cat("\n\n")
}
```

### Co-extracts

We can already aggregate the co-extracts to the protein level for later testing.

```{r}
#| label: chunk-protein-agg
#| message: false
#| warning: false

# select co-extracts and aggregate to the protein level
pe <- pe |>
  addAssay(
    subset(pe[["precursor"]], subset = !histone),
    "precursorCoextr"
  ) |>
  addAssayLink("precursor", "precursorCoextr", "feature_number", "feature_number") |>
  aggregateFeatures(
    i = "precursorCoextr",
    fcol = "protein",
    name = "co-extracts",
    fun = MsCoreUtils::robustSummary
  )
# extract protein data
fs::dir_create(fs::path(quarto::get_running_project_root(), "/out/data/"))
assay(pe[["co-extracts"]]) |>
  signif() |>
  as_tibble() |>
  mutate(protein = rownames(assay(pe[["co-extracts"]])), .before = 1) |>
  readr::write_csv(file = fs::path(quarto::get_running_project_root(), "/out/data/coextract_assay", ext = "csv"))
```

### Usage calculation

First, check if the summarized abundance of histone families is consistent across all samples.
Biologically, this should be true most of the time, except the ratio of H1 to the nucleosome has been found to change, and technical artifacts can break this assumption.
This will help determine whether to do the "variant-agnostic" usage normalization against all histones together or against histone families (see the `hptmUsage::generateReport()` argument of `usage_params`).
If the ratio's between histone families are mostly consistent, then the total summed histone abundance should give us a robust enough backbone for usage normalization.

```{r}
#| label: fig-family-ratio
#| fig-cap: "The ratio's of histone family abundances, summed from all corresponding peptidoforms."
#| message: false
#| warning: false

# subset to histones
pe <- pe |>
  addAssay(
    subset(pe[["precursor"]], subset = histone),
    "precursorHistone"
  ) |> # only histones after feature editing
  addAssayLink("precursor", "precursorHistone", "feature_number", "feature_number")

# QC check for nucleosome composition
hist_abundance_qc <- pe |>
  aggregateFeatures(
    i = "precursorHistone",
    fcol = "histone_family",
    name = "histoneFamily",
    fun = MsCoreUtils::robustSummary,
    maxit = 50
  ) |>
  assay("histoneFamily") |>
  reshape2::melt() |>
  ggplot2::ggplot(aes(x = Var2, y = value, fill = Var1)) +
  geom_bar(position = "fill", stat = "identity", color = "black", linewidth = .1) +
  theme_classic() +
  theme(axis.ticks.x = element_blank()) +
  scale_fill_manual(values = alpha(c("#4c566aff", "#d08770ff", "#5e81acff", "#a3be8cff", "#b48eadff"))) +
  scale_y_continuous(labels = scales::percent) +
  coord_cartesian(expand = FALSE) +
  labs(x = "Run", y = "Histone Abundance (%)", fill = "Histone\nFamily")
# ggsave("./out/floats/fig-family-abundance.png",
#   plot = hist_abundance_qc, width = 3.6, height = 2.5, units = "in", dpi = 600
# ) TODO
hist_abundance_qc
```

Now calculate hPTM usage.

```{r}
#| label: chunk-usage-calculation
#| message: false
#| warning: false

pe <- do.call(calculateUsage, rlang::list2(object = pe, i = "precursorHistone", name = "ptm", !!!params$usage_params))
pe <- do.call(calculateUsage, rlang::list2(object = pe, i = "precursorHistone", name = "variant", target = "variant", params$variant_usage_level))

# export the hPTM usage data
assay(pe[["ptm"]]) |>
  signif() |>
  as_tibble() |>
  mutate(hPTM = rowData(pe[["ptm"]])$hptm, .before = 1) |>
  readr::write_csv(file = fs::path(quarto::get_running_project_root(), "/out/data/hptm_assay", ext = "csv"))
assay(pe[["variant"]]) |>
  signif() |>
  as_tibble() |>
  mutate(histone_group = rowData(pe[["variant"]])$histone_group, .before = 1) |>
  readr::write_csv(file = fs::path(quarto::get_running_project_root(), "/out/data/variant_assay", ext = "csv"))
```

A total of `r length(unique(rowData(pe[["ptm"]])$hptm))` single hPTMs were defined.

Now we can repeat the MDS analysis, using the aggregated assays:

1. Globally normalized co-extracts (**protein** level)
2. Usage-normalized **histone peptidoform** level
3. Usage-normalized **hPTM** level
4. Usage-normalized **histone group** level

::: {.column-page}

MDS plots of all samples after general and usage normalization:

::: {.panel-tabset}

```{r}
#| results: asis

mds_assays <- list()
if (is.null(params$usage_params[["usage_level"]])) usage_level <- "histone" else usage_level <- params$usage_params[["usage_level"]]
precursor_norm_name <- paste0("precursorHistoneNorm", stringr::str_to_sentence(usage_level))
for (viz_assay in c(precursor_norm_name, "variant", "ptm", "co-extracts")) {
  mds_assay <- limma::plotMDS(assay(pe, viz_assay), plot = FALSE) |>
    _[c("x", "y", "var.explained")] |>
    data.frame() |>
    cbind(colData(pe)) |>
    rownames_to_column("sample") |>
    mutate(assay = viz_assay)
  mds_assays[[viz_assay]] <- mds_assay
}
mds_assays <- do.call(rbind, mds_assays)
var_explained <- as_tibble(mds_assays) |>
  slice_max(order_by = var.explained, n = 2, by = assay) |>
  _$var.explained

# plot
tabs <- colnames(colData(pe))[!colnames(colData(pe)) %in% c("outlier", "quantCols", "original_name")]
for (fill_col in tabs) {
  cat("#### ", fill_col, "\n\n", sep = "")
  p <- ggplot(mds_assays, mapping = aes(
    x = x, y = y, fill = .data[[fill_col]],
    size = median_histone_abundance, annotation = rownames(mds_assays)
  )) +
    geom_point(colour = "black", shape = 21) +
    facet_wrap(~assay, nrow = 1, scales = "free") +
    theme_bw() +
    xlab(paste0(
      "Leading logFC dim 1 (",
      paste(round(100 * var_explained[seq(1, length(var_explained), 2)], 2), collapse = " %, "),
      "%)"
    )) +
    ylab(paste0(
      "Leading logFC dim 2 (",
      paste(round(100 * var_explained[seq(2, length(var_explained), 2)], 2), collapse = " %, "),
      "%)"
    ))
  p |>
    plotly::ggplotly() |>
    htmltools::tagList() |>
    print()
  cat("\n\n")
}
```

:::

:::

Finally, the preprocessed dataset and all its assays can be represented as such:

```{r}
#| label: fig-qfeatures
#| fig-cap: "Visual representation of the QFeatures object holding all data and its relations"
#| echo: False

plot(pe)
```

## Differential usage analysis {#sec-da}

### Model building

Start by creating the model formula(e) and relevant contrasts, then proceed with differential usage testing.
For clarification on experimental design matrices, see this excellent guide by Law et al.^[Law, C.W., Zeglinski, K., Dong, X., Alhamdoosh, M., Smyth, G.K. & Ritchie, M.E. (2020). A guide to creating design matrices for gene expression experiments. F1000Res. 2020 Dec 10;9:1444. https://doi.org/10.12688/f1000research.27893.]

```{r}
#| label: fig-designmat
#| fig-cap: "Visualization of the design matrix."
#| fig-subcap: true
#| layout-ncol: 1

# drop runs not in the "Include" column of colData, e.g., QC runs or outliers
pe <- pe[, pe$include]
colData(pe) <- droplevels(colData(pe))

# relevel factors as needed
# TODO
stopifnot("'reference_levels' should be a named vector" = length(params$reference_levels) == length(params$reference_levels_names))
for (i in seq_along(params$reference_levels)) {
  colData(pe)[[params$reference_levels_names[[i]]]] <- forcats::fct_relevel(colData(pe)[[params$reference_levels_names[[i]]]], params$reference_levels[[i]])
}
# purrr::walk2(params$reference_levels, params$reference_levels_names, function(x, y) {
#   colData(pe)[[y]] <- forcats::fct_relevel(colData(pe)[[y]], x)
# })

# create design matrices
model_designs <- lapply(
  params$design_formula,
  \(x) ExploreModelMatrix::VisualizeDesign(colData(pe), designFormula = x, textSizeFitted = 2)
)
names(model_designs) <- params$design_formula_names
# show the experimental design matrix
model_designs[grepl("factor", names(model_designs), fixed = TRUE)] |>
  purrr::map("plotlist") |>
  purrr::walk(print) |>
  invisible()
```

Random effects can be included to account for **categorical** technical factors such as sample preparation batches, study individuals, ...
We can estimate the intra-block correlation to determine whether or not to include factors from the colData as random effects.

```{r}
#| label: chunk-random-effects
#| warning: false

# determine intra-block correlation
for (i in seq_along(model_designs)) {
  potential_batch_cols <- colData(pe)[
    !names(colData(pe)) %in% c(
      "quantCols",
      "original_name",
      "group",
      "include",
      "outlier",
      names(model_designs[[i]]$sampledata)
    )
  ] |>
    names()
  # no point in checking for variables with no duplicates
  potential_batch_cols <- potential_batch_cols[
    purrr::map_lgl(potential_batch_cols, \(x) any(duplicated(colData(pe)[[x]])))
  ]
  for (j in potential_batch_cols) {
    limma::duplicateCorrelation(
      # check only for PTM assay as this is most relevant
      assay(pe, "ptm"),
      model_designs[[i]]$designmatrix,
      block = colData(pe)[[j]]
    ) |>
      _$consensus.correlation[[1]] |>
      (\(x) paste0("Model '", names(model_designs)[[i]], "', ", j, " intra-block correlation = ", x))() |>
      print()
  }
}

# add random intercept(s) to formula(e)
if (all(is.null(params$random_effects))) {
  formulas <- purrr::map(params$design_formula, as.formula)
  names(formulas) <- params$design_formula_names
} else {
  formulas <- purrr::map(params$design_formula, function(x) {
    random_intercepts <- purrr::map_chr(params$random_effects, \(x) paste0("+ (1|", x, ")")) |>
      paste(collapse = " ")
    paste(x, paste(random_intercepts)) |>
      as.formula()
  })
  names(formulas) <- params$design_formula_names
}
```

A **categorical** factor with intra-block correlation > 0.01 can be included as a random effect if this makes sense for the model;
when in doubt, contact your local biostatistician!

### Statistical testing

If the relevant contrasts were supplied, the following sections will contain the differential usage results.
Otherwise, these sections will be empty and the contrasts can be written using the relevant design matrix (see @fig-designmat)

```{r}
#| label: chunk-contrasts

if (!is.null(params$contrasts)) {
  contrasts <- purrr::map2(params$contrasts, params$contrasts_names, \(x, y) purrr::set_names(x, y))
  purrr::iwalk(contrasts, function(x, y) {
    print(paste0("Model ", y, ":"))
    purrr::iwalk(x, \(z, a) print(paste("- Contrast", a, "=", z)))
  })
} else {
  print("No contrasts defined!")
}
```

Now we use MSqRob2^[Goeminne, LudgerJ. E., Gevaert, K., & Clement, L. (2016). Peptide-level Robust Ridge Regression Improves Estimation, Sensitivity, and Specificity in Data-dependent Quantitative Label-free Shotgun Proteomics *. Molecular & Cellular Proteomics, 15(2), 657–668. https://doi.org/10/f78fjf] to fit robust linear mixed models for every protein, precursor, or PTM, and perform testing according to the defined contrasts.

```{r}
#| label: chunk-msqrob
#| warning: false

if (!is.null(params$contrasts)) {
  # construct the contrast matrix
  contrasts_full <- list()
  contrast_matrix <- list()
  ridge_regression <- list()
  for (i in seq_along(formulas)) {
    # ridge regression is only really relevant if including random effects and sufficiently complex
    ridge_regression[[i]] <- !all(is.null(params$random_effects)) &&
      length(labels(terms(formulas[[i]]))) - length(params$random_effects) > 1
    if (ridge_regression[[i]]) {
      # prepend "ridge" to model parameters names to match output from msqrob function
      parameter_names <- paste0("ridge", colnames(model_designs[[i]]$designmatrix))
      # also do the above for the contrasts using regex matches to model parameter names
      # first escape all special characters from parameters to prevent the later regex from not matching
      regex_safe_parnames <- colnames(model_designs[[i]]$designmatrix)
      # longest param first to prevent matching substring e.g. interaction terms
      regex_safe_parnames <- regex_safe_parnames |>
        _[order(nchar(regex_safe_parnames), regex_safe_parnames, decreasing = TRUE)] |>
        str_replace_all(r"---{([\[\]\\*?+(){}^$|.])}---", r"---{\\\1}---") |>
        (\(x) paste0("(", paste0(x, collapse = "|"), ")"))()
      contrasts_full[[i]] <- str_replace_all(
        contrasts[[i]],
        regex_safe_parnames,
        "ridge\\1"
      )
    } else {
      parameter_names <- colnames(model_designs[[i]]$designmatrix)
      contrasts_full[[i]] <- contrasts[[i]]
    }
    contrast_matrix[[i]] <- makeContrast(purrr::map_chr(contrasts_full[[i]], paste, "= 0"), parameterNames = parameter_names)
  }

  # perform hypothesis tests and store relevant results
  # lists to store dataframes
  hypothesis_tests <- list()
  signif_pval_thresh <- list()
  for (viz_assay in c("co-extracts", "variant", precursor_norm_name, "ptm")) {
    for (i in seq_along(formulas)) {
      # model fitting and hypothesis tests using MSqRob2
      pe <- pe |>
        msqrob2::msqrob(
          i = viz_assay,
          formula = formulas[[i]],
          modelColumnName = names(formulas)[[i]],
          robust = TRUE,
          maxitRob = 20,
          ridge = ridge_regression[[i]],
          overwrite = TRUE
        ) |>
        hypothesisTest(
          i = viz_assay,
          contrast = contrast_matrix[[i]],
          modelColumn = names(formulas)[[i]],
          overwrite = TRUE
        )
    }

    # extract hypothesis test results
    hypothesis_tests[[viz_assay]] <- do.call(rbind, rowData(pe[[viz_assay]])[, unlist(contrasts_full)]) |>
      as_tibble() |>
      mutate(
        contrast = {
          purrr::map(contrasts, names) |>
            unlist(use.names = FALSE) |>
            rep(each = nrow(pe[[viz_assay]])) |>
            factor(levels = unlist(purrr::map(contrasts, names))[!duplicated(unlist(purrr::map(contrasts, names)))])
        },
        name = if (viz_assay == precursor_norm_name) {
          rep.int(rowData(pe[[viz_assay]])$precursor, length(unlist(contrasts)))
        } else {
          rep.int(rownames(pe[[viz_assay]]), length(unlist(contrasts)))
        },
        family = rep.int(rowData(pe[[viz_assay]])$histone_family, length(unlist(contrasts))),
        formula = rep(names(formulas), times = purrr::map(contrasts, length) * nrow(pe[[viz_assay]])),
      )

    # calculate BH threshold for each contrast using (rank of first non-significant test
    # / total number of tests * FDR)
    signif_pval_thresh[[viz_assay]] <- hypothesis_tests[[viz_assay]] |>
      group_by(contrast, formula) |>
      summarise(BH_thresh = (sum(adjPval < 0.05, na.rm = TRUE) + 1) / n() * 0.05, .groups = "drop")
  }
} else {
  print("No contrasts defined!")
}
```

### Volcano plots

And now present the significant differences for every contrast:

```{r}
#| label: chunk-volcano
#| output: false

if (!is.null(params$contrasts)) {
  assay_names <- list(
    "co-extracts" = "Co-extracts",
    "variant" = "Histone variants",
    "precursor_placeholder" = "Histone precursors",
    "ptm" = "Histone PTMs"
  )
  names(assay_names)[[3]] <- precursor_norm_name

  volcanos <- list()
  volcano_layout <- list()
  for (viz_assay in c("co-extracts", "variant", precursor_norm_name, "ptm")) {
    for (formula_name in names(formulas)) {
      # static plot
      volcanos[[viz_assay]][[formula_name]] <- hypothesis_tests[[viz_assay]] |>
        filter(formula == formula_name) |>
        droplevels() |>
        ggplot(
          aes(
            x = logFC,
            y = -log10(pval),
            color = adjPval < 0.05,
            shape = if (viz_assay == "co-extracts") {
              NULL
            } else {
              family
            },
            text = if (viz_assay == "co-extracts") {
              name
            } else {
              paste(family, name, sep = "#")
            }
          )
        ) +
        geom_hline(
          data = signif_pval_thresh[[viz_assay]] |> filter(formula == formula_name) |> droplevels(),
          aes(yintercept = -log10(BH_thresh)),
          linetype = "dashed",
          color = "#c44133ff"
        ) +
        geom_vline(xintercept = 0, linetype = "dashed", color = "#253544ff") +
        geom_point() +
        facet_wrap(vars(contrast), scales = "free") +
        theme_bw() +
        theme(plot.title = element_text(face = "bold")) +
        scale_color_manual(values = alpha(c("#253544ff", "#c44133ff"))) +
        coord_cartesian(xlim = c(
          -max(abs(filter(hypothesis_tests[[viz_assay]], formula == formula_name)$logFC)),
          max(abs(filter(hypothesis_tests[[viz_assay]], formula == formula_name)$logFC))
        ))
      # print for testing
      # print(volcanos[[viz_assay]][[formula_name]] +
      #   labs(
      #     x = bquote(log[2](FC)),
      #     y = bquote(-log[10](Pval)),
      #     color = bquote(Pval[BH] < 0.05),
      #     shape = "Histone family",
      #     title = assay_names[[viz_assay]]
      #   ))
      # for output width/height
      volcano_layout[[formula_name]] <- ggplot_build(volcanos[[viz_assay]][[formula_name]])$layout$layout
      # # save figures TODO
      # ggsave(
      #   plot = volcanos[[viz_assay]][[formula_name]] +
      #     labs(
      #       x = bquote(log[2](FC)),
      #       y = bquote(-log[10](Pval)),
      #       color = bquote(Pval[BH] < 0.05),
      #       shape = "Histone family",
      #       title = assay_names[[viz_assay]]
      #     ),
      #   filename = fs::path(quarto::get_running_project_root(), "/out/floats/",
      #     str_replace_all(assay_names[[viz_assay]], fixed(" "), "_"),
      #     "_volcano.pdf"),
      #   width = 40 + 50 * max(volcano_layout[[formula_name]]$COL),
      #   height = 60 * max(volcano_layout[[formula_name]]$ROW),
      #   units = "mm", dpi = 300
      # )
    }
  }
} else {
  print("No contrasts defined!")
}

```

::: {.column-page}

```{r}
#| results: asis
#| out-width: 100%

if (!is.null(params$contrasts)) {
  cat(":::: {.panel-tabset}", "\n\n")
  for (formula_name in names(formulas)) {
    # quarto programmatic tabset
    cat(
      "#### ",
      paste0("Model ", formula_name),
      "\n\n",
      "::::: {.panel-tabset group='assay'}\n\n",
      sep = ""
    )
    for (viz_assay in c("co-extracts", "variant", precursor_norm_name, "ptm")) {
      # quarto programmatic tabset
      cat("##### ", assay_names[[viz_assay]], "\n\n", sep = "")
      # legend label
      if (viz_assay == "co-extracts") {
        legend_shape <- NULL
      } else {
        legend_shape <- "\nHistone family"
      }
      # interactive plot with plotly
      volcanos[[viz_assay]][[formula_name]] |>
        plotly::ggplotly(tooltip = c("text", "x", "y"), height = max(volcano_layout[[formula_name]]$ROW) * 500) |>
        plotly::layout(legend = list(title = list(text = paste0("Pval<sub>BH</sub> < 0.05", legend_shape)))) |>
        htmltools::tagList() |>
        print()
      # end quarto programmatic tabset
      cat("\n\n")
    }
    # end quarto programmatic tabset
    cat(":::::\n\n")
  }
  cat("::::", "\n\n")
} else {
  print("No contrasts defined!")
}
```

:::

## Data export {#sec-export}

Finally, we can write out the volcano plots and results

```{r}
#| label: chunk-results

if (!is.null(params$contrasts)) {
  # write the results from differential abundance/usage analysis
  for (viz_assay in c("co-extracts", "variant", precursor_norm_name, "ptm")) {
    # export results tables
    hypothesis_tests[[viz_assay]] |>
      arrange(pval) |>
      group_by(formula, contrast) |>
      mutate(within_formula_contrast_rank = order(order(pval))) |>
      ungroup() |>
      mutate(
        signif = adjPval < 0.05,
        across(where(is.numeric), ~ signif(., 3))
      ) |>
      readr::write_csv(file = fs::path(quarto::get_running_project_root(), "/out/data/", paste0("contrast_", viz_assay), ext = "csv"))
  }
  archive::archive_write_dir(
    fs::path(quarto::get_running_project_root(), "/out/figures", ext = "zip"),
    fs::path(quarto::get_running_project_root(), "/out/floats/")
  )
  archive::archive_write_dir(
    fs::path(quarto::get_running_project_root(), "/out/assays", ext = "zip"),
    fs::path(quarto::get_running_project_root(), "/out/data/")
  )
} else {
  print("No contrasts defined!")
}

# export final dataset
saveRDS(pe, fs::path(quarto::get_running_project_root(), "ds_processed", ext = "rds"))
```

The results of the differential abundance analysis can be downloaded here:

{{< downloadthis `r fs::path(quarto::get_running_project_root(), "/out/figures", ext = "zip")` label="Download figures" type=info >}}

{{< downloadthis `r fs::path(quarto::get_running_project_root(), "/out/assays", ext = "zip")` label="Download assays" type=info >}}

::: {.callout-note collapse="true"}
## Session Info

```{r}
#| label: chunk-sessionInfo
#|
sessionInfo()
```

:::
